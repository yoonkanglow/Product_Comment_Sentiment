{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the purpose of the notebook is to build a scraper to harvest the Sony Xperia handsets product reviews. Then I will analyse the review in other notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the neccessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json,mechanize,re\n",
    "from lxml import html # using lxml to parse the html page instead of beautiful soup due to its speed\n",
    "from fake_useragent import UserAgent # adding a randomly selected user agent and add it to the browser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "au = UserAgent(cache=False)\n",
    "br =mechanize.Browser() \n",
    "br.set_handle_robots(False) # stop the robot to read the robot txt\n",
    "br.addheaders = [('User-agent', 'rand_UserAgent')] # randomly add the user agent (Browsers eg: firefox) into the browser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_web_data(weblink):\n",
    "    webpage = br.open(weblink)\n",
    "    webtext = webpage.read()\n",
    "    webpage.close()\n",
    "    parsed_page = html.fromstring(webtext)\n",
    "    return parsed_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first go to the result page with the 'xperia' keyword search and grab all the product detail page url for within the first 10 pages and store the links in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weblink_first_part = 'https://www.amazon.co.uk/gp/search/ref=sr_nr_n_1?fst=as%3Aoff&rh=n%3A356496011%2Ck%3Axperia&page='\n",
    "weblink_second_part = '&keywords=xperia&ie=UTF8'\n",
    "link_file = open('xperia_product.txt','a')\n",
    "# weblink_first_part = 'https://www.amazon.co.uk/s/ref=sr_pg_2?rh=n%3A560798%2Cn%3A1340509031%2Cn%3A5362060031%2Cn%3A356496011%2Ck%3Asamsung&page='\n",
    "# weblink_second_part = '&keywords=samsung&ie=UTF8'\n",
    "# link_file = open('samsung_product.txt','a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently in page :1\n",
      "currently in page :2\n",
      "currently in page :3\n",
      "currently in page :4\n",
      "currently in page :5\n",
      "currently in page :6\n",
      "currently in page :7\n",
      "currently in page :8\n",
      "currently in page :9\n",
      "currently in page :10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    parsed_page = get_web_data(weblink_first_part+str(i)+weblink_second_part)\n",
    "#     parsed_page = html.fromstring(webtext)\n",
    "    parsed_text = html.tostring(parsed_page)\n",
    "    matched_result = re.findall('id=\"(result_\\d.)',parsed_text)\n",
    "\n",
    "    for result in matched_result:\n",
    "        try:\n",
    "            link_file.write(parsed_page.xpath('//*[@id=\"'+result.replace('\"','')+'\"]/div/div[2]/div/div/a/@href')[0])\n",
    "            link_file.write('\\n')\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    print 'currently in page :'+str(i)\n",
    "link_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in each product detail page, search for the review page url and then go into the page. In the review page, identify the last page number, then from each review page scrape the review_author, review_date, review_star, review_title, review, plus product name and price information. Then store the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed stage 1\n",
      "last page : 8\n",
      "1\n",
      "passed stage 2\n",
      "2\n",
      "passed stage 2\n",
      "3\n",
      "passed stage 2\n",
      "4\n",
      "passed stage 2\n",
      "5\n",
      "passed stage 2\n",
      "6\n",
      "passed stage 2\n",
      "7\n",
      "passed stage 2\n",
      "8\n",
      "passed stage 2\n",
      "passed stage 1\n",
      "last page : 11\n",
      "1\n",
      "passed stage 2\n",
      "2\n",
      "passed stage 2\n",
      "3\n",
      "passed stage 2\n",
      "4\n",
      "passed stage 2\n",
      "5\n",
      "failed at link : https://www.amazon.co.uk/Sony-Xperia-SIM-Free-Smart-Phone-Mineral-Black/product-reviews/B01L96EDEW/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews5\n",
      "6\n",
      "passed stage 2\n",
      "7\n",
      "passed stage 2\n",
      "8\n",
      "passed stage 2\n",
      "9\n",
      "passed stage 2\n",
      "10\n",
      "passed stage 2\n",
      "11\n",
      "passed stage 2\n",
      "passed stage 1\n",
      "last page : 0\n",
      "passed stage 1\n",
      "last page : 9\n",
      "1\n",
      "passed stage 2\n",
      "2\n",
      "passed stage 2\n",
      "3\n",
      "passed stage 2\n",
      "4\n",
      "passed stage 2\n",
      "5\n",
      "failed at link : https://www.amazon.co.uk/Sony-Xperia-Compact-Smart-Phone-Universe-Black/product-reviews/B01L96ZBZ2/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews5\n",
      "6\n",
      "passed stage 2\n",
      "7\n",
      "passed stage 2\n",
      "8\n",
      "passed stage 2\n",
      "9\n",
      "passed stage 2\n",
      "passed stage 1\n",
      "last page : 0\n"
     ]
    }
   ],
   "source": [
    "weblink_in = open('xperia_product.txt','r').read().split('\\n')\n",
    "review_data = open('xperia_product_reviews_testing.txt','a')\n",
    "\n",
    "# weblink_in = open('samsung_product.txt','r').read().split('\\n')\n",
    "# review_data = open('samsung_product_reviews.txt','a')\n",
    "\n",
    "product_name_review = '//*[@id=\"reviews-medley-footer\"]/div[1]/a/@href'\n",
    "main_web_domain = 'https://www.amazon.co.uk'\n",
    "last_page_path = '//*[@id=\"cm_cr-pagination_bar\"]/ul/li[7]/a/text()'\n",
    "review_list_path = '//*[@id=\"cm_cr-review_list\"]'\n",
    "\n",
    "for link in weblink_in:\n",
    "    try:\n",
    "        parsed_page = get_web_data(link)\n",
    "    \n",
    "        product_name = parsed_page.xpath('//*[@id=\"productTitle\"]/text()')[0].replace('\\n','').strip()\n",
    "        \n",
    "        reviews_pagepart = parsed_page.xpath(product_name_review)[0]\n",
    "        parsed_page = get_web_data(main_web_domain+reviews_pagepart)\n",
    "        \n",
    "        try:\n",
    "            last_page = parsed_page.xpath(last_page_path)[0]\n",
    "        except:\n",
    "            last_page = '0'\n",
    "            \n",
    "        price = parsed_page.xpath('//*[@id=\"cm_cr-product_info\"]/div/div[2]/div/div/div[2]/div[4]/span/span[3]/text()')[0].encode('utf-8')\n",
    "        \n",
    "        print 'passed stage 1'\n",
    "        print 'last page : '+last_page\n",
    "        \n",
    "        try:\n",
    "            for i in range(1,int(last_page)+1):\n",
    "                try:\n",
    "                    print i\n",
    "                    if i == 1:\n",
    "                        parsed_page = parsed_page\n",
    "                    else:\n",
    "                        parsed_page = get_web_data(main_web_domain+reviews_pagepart+'&pageNumber='+str(i))\n",
    "\n",
    "                    print 'passed stage 2'\n",
    "\n",
    "                    html_text = html.tostring(parsed_page.xpath(review_list_path)[0])\n",
    "                #     sub_parsed_page = html.fromstring(html_text)\n",
    "                    review_id_list = re.findall('<div id=\"customer_review-(.*)\" class=\"a-section celwidget',html_text)\n",
    "\n",
    "                    for review in review_id_list:\n",
    "\n",
    "                        html_text = html.tostring(parsed_page.xpath('//*[@id=\"'+review+'\"]')[0])\n",
    "                        sub_parsed_page = html.fromstring(html_text)\n",
    "                        review = sub_parsed_page.xpath('//*[@data-hook=\"review-body\"]/text()')[0].replace('\\n','').encode('utf-8')\n",
    "                        review_title = sub_parsed_page.xpath('//*[@data-hook=\"review-title\"]/text()')[0].encode('utf-8')\n",
    "                        review_date =sub_parsed_page.xpath('//*[@data-hook=\"review-date\"]/text()')[0]\n",
    "                        review_author = sub_parsed_page.xpath('//*[@data-hook=\"review-author\"]/text()')[0].encode('utf-8')\n",
    "                        review_star = sub_parsed_page.xpath('//*[@data-hook=\"review-star-rating\"]/span/text()')[0].replace(' out of 5 stars','')\n",
    "\n",
    "        #                 print review_author+'|'+review_date+'|'+review_star+'|'+review_title+'|'+review\n",
    "        #                 print \"***\"*10\n",
    "                        review_data.write(product_name+'|'+price+'|'+review_author+'|'+review_date+'|'+review_star+'|'+review_title+'|'+review)\n",
    "                        review_data.write('\\n')\n",
    "                except:\n",
    "                    print \"failed at link : \"+main_web_domain+reviews_pagepart+str(i)\n",
    "                    pass\n",
    "        except:\n",
    "            print \"failed at : \"+main_web_domain+reviews_pagepart\n",
    "            pass\n",
    "    except:\n",
    "        print \"failed at link: \"+link\n",
    "        \n",
    "review_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
